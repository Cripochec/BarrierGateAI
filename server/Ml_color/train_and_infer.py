if __name__ == '__main__':
    import os
    import torch
    import torchvision
    import torchvision.transforms as transforms
    from torch.utils.data import DataLoader
    import torch.nn as nn
    import torch.optim as optim
    from torchvision import datasets, models
    import matplotlib.pyplot as plt
    import numpy as np
    from PIL import Image
    from tqdm import tqdm

    # ==== –ù–∞—Å—Ç—Ä–æ–π–∫–∏ ====
    BATCH_SIZE = 32
    NUM_CLASSES = 15  # 14 —Ü–≤–µ—Ç–æ–≤ + "–æ—Å—Ç–∞–ª—å–Ω—ã–µ"
    EPOCHS = 10
    DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    MODEL_PATH = "color_classifier.pth"
    EARLY_STOPPING_PATIENCE = 3  # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —ç–ø–æ—Ö –±–µ–∑ —É–ª—É—á—à–µ–Ω–∏–π –¥–æ –æ—Å—Ç–∞–Ω–æ–≤–∫–∏

    print(f"\nüì¶ –ò—Å–ø–æ–ª—å–∑—É–µ–º–æ–µ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è: {DEVICE}\n")

    # ==== –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è ====
    transform = transforms.Compose([
        transforms.Resize((224, 224)),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406],
                             std=[0.229, 0.224, 0.225])
    ])

    # ==== –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö ====
    print("üîÑ –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞...")
    train_dataset = datasets.ImageFolder('dataset_color/train', transform=transform)
    val_dataset = datasets.ImageFolder('dataset_color/val', transform=transform)
    test_dataset = datasets.ImageFolder('dataset_color/test', transform=transform)

    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)
    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, num_workers=4)
    test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, num_workers=4)

    class_names = train_dataset.classes

    # ==== –ú–æ–¥–µ–ª—å ====
    model = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)
    model.fc = nn.Linear(model.fc.in_features, NUM_CLASSES)
    model = model.to(DEVICE)

    # ==== –û–±—É—á–µ–Ω–∏–µ ====
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=1e-4)

    train_losses = []
    val_accuracies = []

    best_val_accuracy = 0
    epochs_without_improvement = 0

    for epoch in range(EPOCHS):
        print(f"\nüü¢ –≠–ø–æ—Ö–∞ {epoch + 1}/{EPOCHS}")
        model.train()
        total_loss = 0

        train_loop = tqdm(train_loader, desc="üöÇ –û–±—É—á–µ–Ω–∏–µ", leave=False)
        for images, labels in train_loop:
            images, labels = images.to(DEVICE), labels.to(DEVICE)

            outputs = model(images)
            loss = criterion(outputs, labels)

            optimizer.zero_grad()
            loss.backward()
            optimizer.step()

            total_loss += loss.item()
            train_loop.set_postfix(loss=loss.item())

        avg_loss = total_loss / len(train_loader)
        train_losses.append(avg_loss)
        print(f"üîß –°—Ä–µ–¥–Ω–∏–π loss: {avg_loss:.4f}")

        # ==== –í–∞–ª–∏–¥–∞—Ü–∏—è ====
        model.eval()
        correct, total = 0, 0
        val_loop = tqdm(val_loader, desc="üß™ –í–∞–ª–∏–¥–∞—Ü–∏—è", leave=False)
        with torch.no_grad():
            for images, labels in val_loop:
                images, labels = images.to(DEVICE), labels.to(DEVICE)
                outputs = model(images)
                _, predicted = torch.max(outputs.data, 1)
                total += labels.size(0)
                correct += (predicted == labels).sum().item()

        acc = 100 * correct / total
        val_accuracies.append(acc)
        print(f"‚úÖ Validation Accuracy: {acc:.2f}%")

        # ==== Early stopping ====
        if acc > best_val_accuracy:
            best_val_accuracy = acc
            epochs_without_improvement = 0
            # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏
            torch.save(model.state_dict(), f"model_epoch_{epoch+1}.pth")
            print(f"‚úÖ –ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤ model_epoch_{epoch+1}.pth")
        else:
            epochs_without_improvement += 1
            if epochs_without_improvement >= EARLY_STOPPING_PATIENCE:
                print(f"‚ùó –†–∞–Ω–Ω–µ–µ –∑–∞–≤–µ—Ä—à–µ–Ω–∏–µ –Ω–∞ —ç–ø–æ—Ö–µ {epoch + 1}. –ú–æ–¥–µ–ª—å –Ω–µ —É–ª—É—á—à–∞–µ—Ç—Å—è.")
                break

    # ==== –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –≥—Ä–∞—Ñ–∏–∫–æ–≤ ====
    plt.figure(figsize=(10, 5))
    plt.subplot(1, 2, 1)
    plt.plot(train_losses, label="Train Loss")
    plt.xlabel("Epoch")
    plt.ylabel("Loss")
    plt.title("–ü–æ—Ç–µ—Ä–∏ –ø—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏")
    plt.grid(True)
    plt.legend()

    plt.subplot(1, 2, 2)
    plt.plot(val_accuracies, label="Validation Accuracy", color='green')
    plt.xlabel("Epoch")
    plt.ylabel("Accuracy (%)")
    plt.title("–¢–æ—á–Ω–æ—Å—Ç—å –Ω–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏")
    plt.grid(True)
    plt.legend()

    plt.tight_layout()

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≥—Ä–∞—Ñ–∏–∫
    plt.savefig("training_metrics.png")
    print("üìä –ì—Ä–∞—Ñ–∏–∫–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ —Ñ–∞–π–ª: training_metrics.png")

    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –≥—Ä–∞—Ñ–∏–∫
    plt.show()

    # ==== –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –Ω–∞ —Ä–µ–∞–ª—å–Ω–æ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏ ====
    def predict_color(image_path):
        model.eval()
        image = Image.open(image_path).convert("RGB")
        image_tensor = transform(image).unsqueeze(0).to(DEVICE)

        with torch.no_grad():
            output = model(image_tensor)
            _, predicted = torch.max(output, 1)
            predicted_color = class_names[predicted.item()]

        # –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è
        plt.imshow(image)
        plt.title(f"–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–π —Ü–≤–µ—Ç: {predicted_color}")
        plt.axis('off')
        plt.show()
        return predicted_color

    # ==== –ü—Ä–∏–º–µ—Ä –∑–∞–ø—É—Å–∫–∞ ====
    if os.path.exists("car.jpg"):
        color = predict_color("car.jpg")
        print(f"üöó –¶–≤–µ—Ç –∞–≤—Ç–æ–º–æ–±–∏–ª—è: {color}")
    else:
        print("üì∏ –ü–æ–º–µ—Å—Ç–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –º–∞—à–∏–Ω—ã –≤ —Ñ–∞–π–ª 'car.jpg' –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è.")
