import cv2
from ultralytics import YOLO
import torch
from torchvision import models, transforms
from PIL import Image
import matplotlib.pyplot as plt
import easyocr
import numpy as np


def crop_vehicle(image_path: str, visualize, yolo_model=None) -> Image.Image or None:
    # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä–µ–¥–∑–∞–≥—Ä—É–∂–µ–Ω–Ω—É—é –º–æ–¥–µ–ª—å, –µ—Å–ª–∏ –ø–µ—Ä–µ–¥–∞–Ω–∞
    if yolo_model is None:
        yolo_model = YOLO("ML/yolov8n.pt")
    img_bgr = cv2.imread(image_path)
    results = yolo_model(img_bgr)[0]

    for box in results.boxes:
        cls = int(box.cls[0])
        if results.names[cls] in ['car', 'truck', 'bus']:
            x1, y1, x2, y2 = map(int, box.xyxy[0])
            cropped = img_bgr[y1:y2, x1:x2]
            cropped_pil = Image.fromarray(cv2.cvtColor(cropped, cv2.COLOR_BGR2RGB))

            if visualize:
                plt.imshow(cropped_pil)
                plt.title(f"–ù–∞–π–¥–µ–Ω –∞–≤—Ç–æ–º–æ–±–∏–ª—å: –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã ({x1}, {y1}, {x2}, {y2})")
                plt.axis('off')
                plt.show()

            return cropped_pil

    print("‚ùå –ú–∞—à–∏–Ω–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞.")
    return None


def load_color_model(model_path, class_names, device=None):
    if device is None:
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

    model = models.resnet18(weights=None)
    model.fc = torch.nn.Linear(model.fc.in_features, len(class_names))
    model.load_state_dict(torch.load(model_path, map_location=device))
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((224, 224)),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406],
                             std=[0.229, 0.224, 0.225])
    ])

    return model, transform, device


def predict_color(pil_image: Image.Image, model, transform, class_names, device, visualize=False):
    image_tensor = transform(pil_image).unsqueeze(0).to(device)

    with torch.no_grad():
        output = model(image_tensor)
        _, predicted = torch.max(output, 1)
        predicted_color = class_names[predicted.item()]

    if visualize:
        plt.imshow(pil_image)
        plt.title(f"–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–π —Ü–≤–µ—Ç: {predicted_color}")
        plt.axis('off')
        plt.show()

    return predicted_color


def predict_brand(pil_image: Image.Image, model, transform, class_names, device, visualize=False):
    """
    –ü—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞–µ—Ç –º–∞—Ä–∫—É –∞–≤—Ç–æ–º–æ–±–∏–ª—è –ø–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—é —Å –ø–æ–º–æ—â—å—é –æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏.

    :param pil_image: PIL.Image - –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∞–≤—Ç–æ–º–æ–±–∏–ª—è
    :param model: torch.nn.Module - –∑–∞–≥—Ä—É–∂–µ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å –º–∞—Ä–∫–∏
    :param transform: torchvision.transforms - –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è –¥–ª—è –≤—Ö–æ–¥–∞
    :param class_names: list - —Å–ø–∏—Å–æ–∫ –Ω–∞–∑–≤–∞–Ω–∏–π –º–∞—Ä–æ–∫
    :param device: torch.device - —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ –¥–ª—è –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞
    :param visualize: bool - –≤–∏–∑—É–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç
    :return: str - –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω–∞—è –º–∞—Ä–∫–∞
    """
    image_tensor = transform(pil_image).unsqueeze(0).to(device)

    with torch.no_grad():
        output = model(image_tensor)
        _, predicted = torch.max(output, 1)
        predicted_brand = class_names[predicted.item()]

    if visualize:
        plt.imshow(pil_image)
        plt.title(f"–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω–∞—è –º–∞—Ä–∫–∞: {predicted_brand}")
        plt.axis('off')
        plt.show()

    return predicted_brand


def detect_license_plate(img_pil: Image.Image, use_gpu: bool = False, visualize: bool = False, reader=None) -> str:
    """
    –†–∞—Å–ø–æ–∑–Ω–∞—ë—Ç –≥–æ—Å–Ω–æ–º–µ—Ä –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏ –∞–≤—Ç–æ–º–æ–±–∏–ª—è —Å –ø–æ–º–æ—â—å—é easyocr.

    :param img_pil: PIL –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –º–∞—à–∏–Ω—ã
    :param use_gpu: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å GPU (–µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–Ω–æ)
    :param visualize: –í–∏–∑—É–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç —Å —Ä–∞–º–∫–æ–π
    :param reader: –ü—Ä–µ–¥–∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–π easyocr.Reader (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
    :return: –†–∞—Å–ø–æ–∑–Ω–∞–Ω–Ω—ã–π –Ω–æ–º–µ—Ä –∏–ª–∏ '–Ω–æ–º–µ—Ä –Ω–µ –Ω–∞–π–¥–µ–Ω'
    """
    allowed_chars = 'ABEKMHOPCTYX0123456789'
    if reader is None:
        reader = easyocr.Reader(['en'], gpu=use_gpu)
    img_np = cv2.cvtColor(np.array(img_pil), cv2.COLOR_RGB2BGR)

    results = reader.readtext(img_np, allowlist=allowed_chars)

    for bbox, text, conf in results:
        clean_text = ''.join(char for char in text if char in allowed_chars)
        if 6 <= len(clean_text) <= 10 and conf > 0.5:
            print(f"üì∑ –ì–æ—Å–Ω–æ–º–µ—Ä: {clean_text} (—É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {conf:.2f})")

            if visualize:
                pts = np.array(bbox, dtype=np.int32)
                cv2.polylines(img_np, [pts], isClosed=True, color=(0, 255, 0), thickness=2)
                cv2.putText(img_np, clean_text, (pts[0][0], pts[0][1] - 10),
                            cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)

                # –û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å matplotlib
                plt.imshow(cv2.cvtColor(img_np, cv2.COLOR_BGR2RGB))
                plt.title(f"–†–∞—Å–ø–æ–∑–Ω–∞–Ω –Ω–æ–º–µ—Ä: {clean_text}")
                plt.axis('off')
                plt.show()

            return clean_text

    if visualize:
        plt.imshow(img_pil)
        plt.title("–ì–æ—Å–Ω–æ–º–µ—Ä –Ω–µ –Ω–∞–π–¥–µ–Ω")
        plt.axis('off')
        plt.show()

    return "–Ω–æ–º–µ—Ä –Ω–µ –Ω–∞–π–¥–µ–Ω"
